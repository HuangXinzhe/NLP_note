{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 词袋模型\n",
    "## 在NLP任务中初始的处理是对文本数据进行分句与分词\n",
    "### 词袋模型计算句子相似度过程\n",
    "- 1.对文本数据进行分句与分词\n",
    "- 2.构建词表（语料库）\n",
    "- 3.构建词表（语料库）的数字映射\n",
    "- 4.建立句子向量表示\n",
    "- 5.计算相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"I love sky, I love sea.\"\n",
    "sent2 = \"I like running, I love reading.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词\n",
    "- 英文分词\n",
    "    - NLTK\n",
    "- 中文分词\n",
    "    - jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "sents = [sent1, sent2]\n",
    "texts = [[word for word in word_tokenize(sent)] for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I', 'love', 'sky', ',', 'I', 'love', 'sea', '.'],\n",
       " ['I', 'like', 'running', ',', 'I', 'love', 'reading', '.']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、构建语料库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list = []\n",
    "for text in texts:\n",
    "    all_list += text\n",
    "corpus = set(all_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',', '.', 'I', 'like', 'love', 'reading', 'running', 'sea', 'sky'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、语料库构建数字映射\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dict = dict(zip(corpus, range(len(corpus))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 0,\n",
       " 'I': 1,\n",
       " ',': 2,\n",
       " '.': 3,\n",
       " 'running': 4,\n",
       " 'sky': 5,\n",
       " 'sea': 6,\n",
       " 'like': 7,\n",
       " 'reading': 8}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、建立句子的向量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (1, 2), (2, 1), (3, 1), (4, 0), (5, 1), (6, 1), (7, 0), (8, 0)]\n",
      "[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 0), (6, 0), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "def vector_rep(text, corpus_dict):\n",
    "    vec = []\n",
    "    for key in corpus_dict.keys():\n",
    "        if key in text:\n",
    "            vec.append((corpus_dict[key], text.count(key)))\n",
    "        else:\n",
    "            vec.append((corpus_dict[key], 0))\n",
    "\n",
    "    vec = sorted(vec, key= lambda x: x[0])\n",
    "\n",
    "    return vec\n",
    "\n",
    "vec1 = vector_rep(texts[0], corpus_dict)\n",
    "vec2 = vector_rep(texts[1], corpus_dict)\n",
    "print(vec1)\n",
    "print(vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 句子相似度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def similarity_with_2_sents(vec1, vec2):\n",
    "    inner_product = 0\n",
    "    square_length_vec1 = 0\n",
    "    square_length_vec2 = 0\n",
    "    for tup1, tup2 in zip(vec1, vec2):\n",
    "        inner_product += tup1[1]*tup2[1]\n",
    "        square_length_vec1 += tup1[1]**2\n",
    "        square_length_vec2 += tup2[1]**2\n",
    "\n",
    "    return (inner_product/sqrt(square_length_vec1*square_length_vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "两个句子的余弦相似度为： 0.7303。\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = similarity_with_2_sents(vec1, vec2)\n",
    "print('两个句子的余弦相似度为： %.4f。'%cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用gensim计算句子相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I', 'love', 'sky', ',', 'I', 'love', 'sea', '.'], ['I', 'like', 'running', ',', 'I', 'love', 'reading', '.']]\n",
      "Similarity<2 documents in 0 shards stored under -Similarity-index>\n",
      "利用gensim计算得到两个句子的相似度： 0.7303。\n"
     ]
    }
   ],
   "source": [
    "sent1 = \"I love sky, I love sea.\"\n",
    "sent2 = \"I like running, I love reading.\"\n",
    "\n",
    "from nltk import word_tokenize\n",
    "sents = [sent1, sent2]\n",
    "texts = [[word for word in word_tokenize(sent)] for sent in sents]\n",
    "print(texts)\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.similarities import Similarity\n",
    "\n",
    "#  语料库\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\n",
    "# 利用doc2bow作为词袋模型\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "similarity = Similarity('-Similarity-index', corpus, num_features=len(dictionary))\n",
    "print(similarity)\n",
    "\n",
    "# 获取句子的相似度\n",
    "new_sensence = sent1\n",
    "test_corpus_1 = dictionary.doc2bow(word_tokenize(new_sensence))\n",
    "\n",
    "cosine_sim = similarity[test_corpus_1][1]\n",
    "print(\"利用gensim计算得到两个句子的相似度： %.4f。\"%cosine_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "common8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
